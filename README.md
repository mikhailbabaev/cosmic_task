# О проекте

В этом проекте развернута численная модель и подключён инструмент для определения текущего времени.  
В качестве модели используется **llama3.2** из Ollama.

Для работы с локальной моделью использован фреймворк **LangChain**.  
В частности, применён агент типа `ZERO_SHOT_REACT_DESCRIPTION`, который умеет вызывать инструмент `get_current_time` при запросах времени.

Модель не идеальна и даёт правильный ответ на вопрос **What time is it?** примерно в одном из трёх-четырёх случаев.

---

# Установка и запуск
Для корректной работы выполните следующие шаги:

1. **Установите Ollama**

Если у вас отсутствует Ollama
Перейдите на официальный сайт Ollama и скачайте приложение под вашу ОС.

2. **Загрузите модель llama3.2**

В терминале выполните команду:
```bash
ollama pull llama3.2
```

3. **Клонируйте репозиторий и установите зависимости**
```bash
git clone <your_repo>
cd <your_repo>
python -m venv .venv
source .venv/bin/activate   # для Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

4. **Запустите проект**
```bash
langgraph dev
```
